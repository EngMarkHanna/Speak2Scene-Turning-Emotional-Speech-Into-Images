{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4h_DOJUBzbQ"
      },
      "source": [
        "#Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdBNNyGgnPq7"
      },
      "outputs": [],
      "source": [
        "!pip install torchcodec --quiet\n",
        "!pip install torchinfo --quiet\n",
        "!pip install transformers accelerate sentencepiece torchaudio diffusers datasets soundfile pillow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz54_9LJHzXY"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7_UoTPcHy__"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import soundfile as sf\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets\n",
        "from torchvision.models import vit_b_16\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset\n",
        "\n",
        "from PIL import Image\n",
        "from diffusers import FluxPipeline\n",
        "from transformers import WhisperProcessor, WhisperModel, WhisperForConditionalGeneration, pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "\n",
        "import gc\n",
        "import json\n",
        "import uuid\n",
        "import time\n",
        "import random\n",
        "import librosa\n",
        "import logging\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "from huggingface_hub import login\n",
        "login()\n",
        "os.environ[\"HF_TOKEN\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VfJErflGtnN"
      },
      "source": [
        "#Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the mixed dataset (we merged) From Kaggle, unzip it and copy it to /content/.\n",
        "\n",
        "Check and delete corrupted files.\n",
        "Setup dataloaders and preprocess data, make it compatible with Whisper."
      ],
      "metadata": {
        "id": "MCtyKpJ1chAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "B1XOjZ9gGqp9"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"kamilhanna/emotion-dataset\", force_download=True)\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRWGmOTdtbbZ"
      },
      "outputs": [],
      "source": [
        "!mv \"{path}\" \"/content\"\n",
        "!mv \"/content/1/content/Emotion\" \"/content/\"\n",
        "!rm -rf \"/content/1\"\n",
        "\n",
        "# #Dropping this class cause low data\n",
        "!rm -rf \"/content/Emotion/calm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQILCMPBSG2X"
      },
      "outputs": [],
      "source": [
        "#Detete corrupted files\n",
        "def clean_corrupted_audio(root):\n",
        "    removed = 0\n",
        "    checked = 0\n",
        "\n",
        "    print(f\"Scanning audio under: {root}\\n\")\n",
        "\n",
        "    for folder, _, files in os.walk(root):\n",
        "        for f in files:\n",
        "            if not f.lower().endswith((\".wav\", \".m4a\")):\n",
        "                continue\n",
        "\n",
        "            path = os.path.join(folder, f)\n",
        "            checked += 1\n",
        "\n",
        "            try:\n",
        "                audio, sr = torchaudio.load(path)\n",
        "            except Exception as e:\n",
        "                print(f\"[CORRUPTED] Removing: {path}   -->   {e}\")\n",
        "                try:\n",
        "                    os.remove(path)\n",
        "                    removed += 1\n",
        "                except Exception as re:\n",
        "                    print(f\"[ERROR] Could not delete {path}: {re}\")\n",
        "                continue\n",
        "\n",
        "    print(\"\\n===== SUMMARY =====\")\n",
        "    print(f\"Checked:  {checked} files\")\n",
        "    print(f\"Removed:  {removed} corrupted files\\n\")\n",
        "    return removed\n",
        "\n",
        "clean_corrupted_audio(\"/content/Emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEYMjBREOWvR"
      },
      "outputs": [],
      "source": [
        "#Setup dataloaders\n",
        "\n",
        "def audio_loader(path):\n",
        "    audio, sr = torchaudio.load(path)\n",
        "    # mono\n",
        "    if audio.shape[0] > 1:\n",
        "        audio = audio.mean(dim=0)\n",
        "    else:\n",
        "        audio = audio[0]\n",
        "    # resample\n",
        "    if sr != 16000:\n",
        "        audio = torchaudio.functional.resample(audio, sr, 16000)\n",
        "\n",
        "    return audio.contiguous()\n",
        "\n",
        "full_dataset = datasets.DatasetFolder(\n",
        "    root=\"/content/Emotion\",\n",
        "    loader=audio_loader,\n",
        "    extensions=(\"wav\", \"m4a\"),\n",
        "    transform=None\n",
        ")\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "num_classes = len(full_dataset.classes)\n",
        "print(f\"number of classes is {num_classes}\\nSize of train dataset {len(train_dataset)}\\nSize of val dataset {len(val_dataset)}\\nSize of test dataset {len(test_dataset)}\")\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
        "\n",
        "print(\"Class â†’ Index mapping:\")\n",
        "for cls_name, idx in full_dataset.class_to_idx.items():\n",
        "    print(f\"{cls_name} --> {idx}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WhisperCollate:\n",
        "    processor: WhisperProcessor\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        audios = []\n",
        "        labels = []\n",
        "\n",
        "        for audio_tensor, label in batch:\n",
        "          audio = audio_tensor.squeeze().float().cpu().numpy()\n",
        "          audios.append(audio)\n",
        "          labels.append(label)\n",
        "\n",
        "        inputs = self.processor(\n",
        "            audios,\n",
        "            sampling_rate=16000,\n",
        "            padding=\"max_length\",\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"input_features\": inputs.input_features,\n",
        "            \"attention_mask\": inputs.attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "#Here we had some problems when batch size was 64 and high num of workers\n",
        "collate_fn = WhisperCollate(processor)\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train MLP From Whisper Encoded data"
      ],
      "metadata": {
        "id": "nPkoGGmadOu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of doing encoder forward pass + MLP forward pass each time to train.\n",
        "\n",
        "Convert all audio files to hidden state of encoder and create a new dataset.\n",
        "\n",
        "Train MLP."
      ],
      "metadata": {
        "id": "hXFVuXovd5FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_embeddings(model, dataloader, save_path):\n",
        "    model.eval()\n",
        "    all_embs = []\n",
        "    all_labels = []\n",
        "    skipped_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Extracting\"):\n",
        "            if batch is None:\n",
        "                skipped_batches += 1\n",
        "                logger.warning(f\"Skipped batch (total: {skipped_batches})\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                feats = batch[\"input_features\"].cuda()\n",
        "                mask = batch[\"attention_mask\"].cuda()\n",
        "                labels = batch[\"labels\"]\n",
        "\n",
        "                enc = model.encoder(\n",
        "                    input_features=feats,\n",
        "                    attention_mask=mask,\n",
        "                    return_dict=True\n",
        "                ).last_hidden_state\n",
        "                pooled = enc.mean(dim=1).cpu()\n",
        "\n",
        "                all_embs.append(pooled)\n",
        "                all_labels.append(labels)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing batch: {type(e).__name__} - {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    if len(all_embs) == 0:\n",
        "        logger.error(\"No embeddings extracted! Check your data.\")\n",
        "        return\n",
        "\n",
        "    X = torch.cat(all_embs, dim=0)\n",
        "    y = torch.cat(all_labels, dim=0)\n",
        "\n",
        "    torch.save((X, y), save_path)\n",
        "    print(f\"Saved {len(X)} embeddings to {save_path} (Skipped {skipped_batches} batches)\")"
      ],
      "metadata": {
        "id": "ujrvpJMqdUGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embeddings\n",
        "model = WhisperModel.from_pretrained(\"openai/whisper-large-v3\").cuda()\n",
        "\n",
        "extract_embeddings(model, train_loader, \"train_emb.pt\")\n",
        "extract_embeddings(model, val_loader, \"val_emb.pt\")\n",
        "extract_embeddings(model, test_loader, \"test_emb.pt\")"
      ],
      "metadata": {
        "id": "AZJUO0l_f2_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset class for whisper encoder embeddings used for MLP training\n",
        "class EmbDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.float()\n",
        "        self.y = y.long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "path = \"/content/drive/MyDrive/GenAI/Project\"\n",
        "X_train, y_train = torch.load(f\"{path}/train_emb.pt\")\n",
        "X_val, y_val = torch.load(f\"{path}/val_emb.pt\")\n",
        "X_test, y_test = torch.load(f\"{path}/test_emb.pt\")\n",
        "train_ds = EmbDataset(X_train, y_train)\n",
        "val_ds   = EmbDataset(X_val, y_val)\n",
        "test_ds  = EmbDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 4\n",
        "train_loader_mlp = DataLoader(train_ds,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           shuffle=True,\n",
        "                           num_workers=NUM_WORKERS,\n",
        "                           pin_memory=True)\n",
        "val_loader_mlp = DataLoader(val_ds,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           shuffle=False,\n",
        "                           num_workers=NUM_WORKERS,\n",
        "                           pin_memory=True)\n",
        "test_loader_mlp = DataLoader(test_ds,\n",
        "                           batch_size=BATCH_SIZE,\n",
        "                           shuffle=False,\n",
        "                           num_workers=NUM_WORKERS,\n",
        "                           pin_memory=True)\n",
        "num_classes = len(y_train.unique())\n",
        "print(num_classes)"
      ],
      "metadata": {
        "id": "kMzgjJuegBt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_HIDDEN_DIMENSION = 1280\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # hidden_1 = MODEL_HIDDEN_DIMENSION // 2\n",
        "        # hidden_2 = MODEL_HIDDEN_DIMENSION // 4\n",
        "        # hidden_3 = MODEL_HIDDEN_DIMENSION // 8\n",
        "\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(MODEL_HIDDEN_DIMENSION, MODEL_HIDDEN_DIMENSION // 2),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.Linear(MODEL_HIDDEN_DIMENSION // 2, MODEL_HIDDEN_DIMENSION // 4),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     nn.Linear(MODEL_HIDDEN_DIMENSION // 4, num_classes)\n",
        "        # )\n",
        "\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(MODEL_HIDDEN_DIMENSION, hidden_1),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_1),\n",
        "\n",
        "        #     nn.Linear(hidden_1, hidden_1),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_1),\n",
        "\n",
        "        #     nn.Linear(hidden_1, hidden_1),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_1),\n",
        "\n",
        "        #     nn.Linear(hidden_1, hidden_1),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_1),\n",
        "\n",
        "        #     nn.Linear(hidden_1, hidden_2),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_2),\n",
        "\n",
        "        #     nn.Linear(hidden_2, hidden_2),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_2),\n",
        "\n",
        "        #     nn.Linear(hidden_2, hidden_2),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_2),\n",
        "\n",
        "        #     nn.Linear(hidden_2, hidden_3),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_3),\n",
        "\n",
        "        #     nn.Linear(hidden_3, num_classes)\n",
        "        # )\n",
        "\n",
        "        #0.77\n",
        "        # hidden_1 = 1024\n",
        "        # hidden_2 = 512\n",
        "        # hidden_3 = 256\n",
        "        # hidden_4 = 128\n",
        "        # hidden_5 = 64\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(MODEL_HIDDEN_DIMENSION, hidden_1),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_1),\n",
        "\n",
        "        #     nn.Linear(hidden_1, hidden_2),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_2),\n",
        "\n",
        "        #     nn.Linear(hidden_2, hidden_3),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_3),\n",
        "\n",
        "        #     nn.Linear(hidden_3, hidden_3),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_3),\n",
        "\n",
        "        #     nn.Linear(hidden_3, hidden_4),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_4),\n",
        "\n",
        "        #     nn.Linear(hidden_4, hidden_5),\n",
        "        #     nn.GELU(),\n",
        "        #     nn.Dropout(0.15),\n",
        "        #     nn.BatchNorm1d(hidden_5),\n",
        "\n",
        "        #     nn.Linear(hidden_5, num_classes)\n",
        "        # )\n",
        "\n",
        "        #83 + 84% test\n",
        "        hidden_1 = 1024\n",
        "        hidden_2 = 512\n",
        "        hidden_3 = 256\n",
        "        hidden_4 = 128\n",
        "        hidden_5 = 64\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(MODEL_HIDDEN_DIMENSION, MODEL_HIDDEN_DIMENSION * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(MODEL_HIDDEN_DIMENSION * 2),\n",
        "\n",
        "            nn.Linear(MODEL_HIDDEN_DIMENSION * 2, hidden_1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(hidden_1),\n",
        "\n",
        "            nn.Linear(hidden_1, hidden_2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(hidden_2),\n",
        "\n",
        "            nn.Linear(hidden_2, hidden_3),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(hidden_3),\n",
        "\n",
        "            nn.Linear(hidden_3, hidden_3),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(hidden_3),\n",
        "\n",
        "            nn.Linear(hidden_3, hidden_4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(hidden_4),\n",
        "\n",
        "            nn.Linear(hidden_4, hidden_5),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.BatchNorm1d(hidden_5),\n",
        "\n",
        "            nn.Linear(hidden_5, num_classes)\n",
        "        )\n",
        "\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(1280, 1024),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.2),\n",
        "\n",
        "        #     nn.Linear(1024, 512),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.2),\n",
        "\n",
        "        #     nn.Linear(512, 256),\n",
        "        #     nn.ReLU(),\n",
        "\n",
        "        #     nn.Linear(256, num_classes)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "model = EmotionClassifier(num_classes).cuda()\n",
        "\n",
        "summary(model, input_size=(1, MODEL_HIDDEN_DIMENSION))"
      ],
      "metadata": {
        "id": "VgKF8fKpgQuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_from_logits(logits, labels):\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    return (preds == labels).float().mean().item()\n",
        "\n",
        "def train_model(model, train_loader_mlp, val_loader_mlp, num_epochs=20):\n",
        "\n",
        "    model = model.cuda()\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    #     optimizer, mode=\"max\", factor=0.5, patience=3, min_lr=1e-6\n",
        "    # )\n",
        "    T_max = 300\n",
        "    eta_min = 1e-6\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=T_max,\n",
        "        eta_min=eta_min\n",
        "    )\n",
        "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    #     optimizer,\n",
        "    #     max_lr=3e-4,\n",
        "    #     steps_per_epoch=len(train_loader_mlp),\n",
        "    #     epochs=num_epochs,\n",
        "    #     pct_start=0.3,\n",
        "    # )\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "\n",
        "        pbar = tqdm(train_loader_mlp, desc=\"Training\", leave=False)\n",
        "        for batch in pbar:\n",
        "            X, y = batch\n",
        "            X, y = X.cuda(), y.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            out = model(X)\n",
        "\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            acc = accuracy_from_logits(out, y)\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_acc += acc\n",
        "\n",
        "            pbar.set_postfix(loss=loss.item(), acc=acc)\n",
        "\n",
        "        train_loss /= len(train_loader_mlp)\n",
        "        train_acc /= len(train_loader_mlp)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(val_loader_mlp, desc=\"Validation\", leave=False)\n",
        "            for batch in pbar:\n",
        "                X, y = batch\n",
        "                X, y = X.cuda(), y.cuda()\n",
        "\n",
        "                out = model(X)\n",
        "\n",
        "                loss = criterion(out, y)\n",
        "                acc = accuracy_from_logits(out, y)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_acc += acc\n",
        "\n",
        "                pbar.set_postfix(loss=loss.item(), acc=acc)\n",
        "\n",
        "        val_loss /= len(val_loader_mlp)\n",
        "        val_acc /= len(val_loader_mlp)\n",
        "\n",
        "\n",
        "        # scheduler.step(val_acc)\n",
        "        scheduler.step()\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "\n",
        "        if (epoch +  1) % 10 == 0:\n",
        "          print(\n",
        "              f\"Epoch {epoch+1} Summary:\\n\"\n",
        "              f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\\n\"\n",
        "              f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\\n\"\n",
        "              f\"  LR:         {optimizer.param_groups[0]['lr']:.6f}\\n\"\n",
        "              f\"  Best Val Acc So Far: {best_val_acc:.4f}\"\n",
        "          )\n",
        "\n",
        "    print(\"\\nTraining finished.\")\n",
        "    return best_val_acc\n",
        "model = EmotionClassifier(num_classes)\n",
        "train_model(model, train_loader_mlp, val_loader_mlp, num_epochs=300)"
      ],
      "metadata": {
        "id": "Cah3OhtGgKy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Trained MLP"
      ],
      "metadata": {
        "id": "W3hAND8Vgx3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test(model, test_loader_mlp):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader_mlp:\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            logits = model(X)\n",
        "            preds = logits.argmax(dim=-1)\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(y.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    test_acc = accuracy_score(all_labels, all_preds)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return test_acc, cm\n",
        "\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "test_acc, cm = evaluate_test(model, test_loader_mlp)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ucFVHsj2gzhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class names\n",
        "class_names = [\n",
        "    \"angry\", \"contempt\", \"disgust\", \"fear\",\n",
        "    \"happy\", \"neutral\", \"sad\", \"surprised\"\n",
        "]\n",
        "\n",
        "\n",
        "cm_float = cm.astype(float)\n",
        "\n",
        "\n",
        "TP = np.diag(cm_float)\n",
        "\n",
        "\n",
        "FP = np.sum(cm_float, axis=0) - TP\n",
        "\n",
        "\n",
        "FN = np.sum(cm_float, axis=1) - TP\n",
        "\n",
        "TN = np.sum(cm_float) - (TP + FP + FN)\n",
        "\n",
        "\n",
        "precision = TP / (TP + FP + 1e-9)\n",
        "recall = TP / (TP + FN + 1e-9)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "\n",
        "true_accuracy = TP / (TP + FN + 1e-9)\n",
        "\n",
        "\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"Class\": class_names,\n",
        "    \"True Accuracy\": true_accuracy,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1 Score\": f1\n",
        "})\n",
        "\n",
        "print(df_metrics)\n",
        "\n",
        "\n",
        "overall_accuracy = TP.sum() / cm.sum()\n",
        "print(\"\\nOverall True Accuracy:\", overall_accuracy)"
      ],
      "metadata": {
        "id": "yh4eoSPIgvOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try SVM instead of MLP (Check if problem is simpler, Did not work well)"
      ],
      "metadata": {
        "id": "VXcRYWF3iN1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loader_to_numpy(data_loader):\n",
        "    X_list, y_list = [], []\n",
        "    for X, y in data_loader:\n",
        "        X_list.append(X.numpy())\n",
        "        y_list.append(y.numpy())\n",
        "    return np.vstack(X_list), np.hstack(y_list)\n",
        "\n",
        "\n",
        "X_train_np, y_train_np = loader_to_numpy(train_loader_mlp)\n",
        "X_val_np,   y_val_np   = loader_to_numpy(val_loader_mlp)\n",
        "X_test_np,  y_test_np  = loader_to_numpy(test_loader_mlp)\n",
        "\n",
        "print(X_train_np.shape, y_train_np.shape)\n",
        "print(X_test_np.shape, y_test_np.shape)\n"
      ],
      "metadata": {
        "id": "pPowjs6KiWXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = LinearSVC(\n",
        "    C=0.7,\n",
        "    class_weight=\"balanced\",\n",
        "    max_iter=5000\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train_np, y_train_np)\n",
        "print(\"SVM training complete.\")\n",
        "\n",
        "#or\n",
        "\n",
        "# svm_rbf = SVC(\n",
        "#     kernel='rbf',\n",
        "#     C=4,\n",
        "#     gamma='scale',\n",
        "#     class_weight=\"balanced\"\n",
        "# )\n",
        "\n",
        "# svm_rbf.fit(X_train_np, y_train_np)\n",
        "\n",
        "# svm_model = svm_rbf\n",
        "# y_pred_rbf = svm_model.predict(X_test_np)\n",
        "# print(\"RBF Test Accuracy:\", accuracy_score(y_test_np, y_pred_rbf))\n",
        "\n"
      ],
      "metadata": {
        "id": "RRdRysGKiWUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate SVM (Check if problem is simpler, Did not work well)"
      ],
      "metadata": {
        "id": "3_-bY45LiuxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_model.predict(X_test_np)\n",
        "\n",
        "test_acc = accuracy_score(y_test_np, y_pred)\n",
        "cm = confusion_matrix(y_test_np, y_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_np, y_pred))\n"
      ],
      "metadata": {
        "id": "1e8JqJmsiWRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"SVM Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MdBut5l3iWKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    \"angry\", \"contempt\", \"disgust\", \"fear\",\n",
        "    \"happy\", \"neutral\", \"sad\", \"surprised\"\n",
        "]\n",
        "\n",
        "cm_float = cm.astype(float)\n",
        "\n",
        "TP = np.diag(cm_float)\n",
        "FP = np.sum(cm_float, axis=0) - TP\n",
        "FN = np.sum(cm_float, axis=1) - TP\n",
        "TN = np.sum(cm_float) - (TP + FP + FN)\n",
        "\n",
        "precision = TP / (TP + FP + 1e-9)\n",
        "recall = TP / (TP + FN + 1e-9)\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "true_acc = TP / (TP + FN + 1e-9)\n",
        "\n",
        "df_metrics = pd.DataFrame({\n",
        "    \"Class\": class_names,\n",
        "    \"True Accuracy\": true_acc,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1 Score\": f1\n",
        "})\n",
        "\n",
        "print(df_metrics)\n",
        "\n",
        "overall_accuracy = TP.sum() / cm.sum()\n",
        "print(\"\\nOverall True Accuracy:\", overall_accuracy)\n"
      ],
      "metadata": {
        "id": "68e9uVMPitxR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1VfJErflGtnN",
        "wwm70ck1Aldr",
        "_Qb0UY-thCx5",
        "58AbwdkehJKO",
        "EuCL4KICk-hF"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}